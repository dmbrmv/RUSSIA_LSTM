{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "\n",
    "import xarray as xr\n",
    "import dask\n",
    "xr.set_options(display_style=\"html\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "from functools import reduce\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import time\n",
    "import tqdm.notebook as tq\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_big_from_MP(WS_geometry):\n",
    "    \"\"\"\n",
    "    \n",
    "    Function return only biggest polygon \n",
    "    from multipolygon WS\n",
    "    It's the real WS, and not malfunctioned part of it\n",
    "    \n",
    "    \"\"\"\n",
    "    if type(WS_geometry) == MultiPolygon:\n",
    "        big_area = [polygon_area(lats=polygon.exterior.coords.xy[1],\n",
    "                                 lons=polygon.exterior.coords.xy[0])\n",
    "                    for polygon in WS_geometry]\n",
    "        WS_geometry = WS_geometry[np.argmax(big_area)]\n",
    "    else:\n",
    "        WS_geometry = WS_geometry\n",
    "    return WS_geometry\n",
    "\n",
    "\n",
    "def polygon_area(lats, lons, radius=6378137):\n",
    "    \"\"\"\n",
    "    Computes area of spherical polygon, assuming spherical Earth. \n",
    "    Returns result in ratio of the sphere's area if the radius is specified.\n",
    "    Otherwise, in the units of provided radius.\n",
    "    lats and lons are in degrees.\n",
    "    \"\"\"\n",
    "    from numpy import (arctan2, cos, sin, sqrt,\n",
    "                       pi, append, diff)\n",
    "\n",
    "    lats, lons = np.deg2rad(lats), np.deg2rad(lons)\n",
    "    # Line integral based on Green's Theorem, assumes spherical Earth\n",
    "\n",
    "    #close polygon\n",
    "    if lats[0] != lats[-1]:\n",
    "        lats = append(lats, lats[0])\n",
    "        lons = append(lons, lons[0])\n",
    "\n",
    "    #colatitudes relative to (0,0)\n",
    "    a = sin(lats/2)**2 + cos(lats) * sin(lons/2)**2\n",
    "    colat = 2*arctan2(sqrt(a), sqrt(1-a))\n",
    "\n",
    "    #azimuths relative to (0,0)\n",
    "    az = arctan2(cos(lats) * sin(lons), sin(lats)) % (2*pi)\n",
    "\n",
    "    # Calculate diffs\n",
    "    # daz = diff(az) % (2*pi)\n",
    "    daz = diff(az)\n",
    "    daz = (daz + pi) % (2 * pi) - pi\n",
    "\n",
    "    deltas = diff(colat)/2\n",
    "    colat = colat[0:-1]+deltas\n",
    "\n",
    "    # Perform integral\n",
    "    integrands = (1-cos(colat)) * daz\n",
    "\n",
    "    # Integrate\n",
    "    area = abs(sum(integrands))/(4*pi)\n",
    "\n",
    "    area = min(area, 1-area)\n",
    "    if radius is not None:  # return in units of radius\n",
    "        return area * 4 * pi * radius**2 / 10**6\n",
    "    else:  # return in ratio of sphere total area\n",
    "        return area / 10**6\n",
    "\n",
    "\n",
    "def find_extent(ws):\n",
    "    \"\"\"\n",
    "    ws - geometry of watershed of interest\n",
    "\n",
    "    Return list of exterior of watershed by 0.25 degree\n",
    "    (equal to ERA5 grid)\n",
    "    \"\"\"\n",
    "\n",
    "    def x_round(x):\n",
    "        return round(x*4)/4\n",
    "\n",
    "    LONS, LATS = ws.exterior.xy\n",
    "    max_LAT = max(LATS)\n",
    "    max_LON = max(LONS)\n",
    "    min_LAT = min(LATS)\n",
    "    min_LON = min(LONS)\n",
    "\n",
    "    return [x_round(min_LON), x_round(max_LON),\n",
    "            x_round(min_LAT), x_round(max_LAT)]\n",
    "\n",
    "\n",
    "def create_GDF(shape):\n",
    "    \"\"\"\n",
    "    \n",
    "    create geodataframe with given shape\n",
    "    as a geometry\n",
    "    \n",
    "    \"\"\"\n",
    "    gdf_your_WS = select_big_from_MP(WS_geometry=shape)\n",
    "    ### WS from your data\n",
    "    gdf_your_WS = gpd.GeoSeries([gdf_your_WS])\n",
    "\n",
    "    ### Create extra gdf to use geopandas functions\n",
    "    gdf_your_WS = gpd.GeoDataFrame({'geometry': gdf_your_WS})\n",
    "    gdf_your_WS = gdf_your_WS.set_crs('EPSG:4326')\n",
    "\n",
    "    return gdf_your_WS\n",
    "\n",
    "\n",
    "def select_NC_by_extent(nc, shape):\n",
    "    \"\"\"\n",
    "    \n",
    "    select net_cdf by extent of given shape\n",
    "    \n",
    "    return masked net_cdf\n",
    "    \n",
    "    \"\"\"\n",
    "    if 'latitude' in nc.dims:\n",
    "        nc = nc.rename({'latitude': 'lat', 'longitude': 'lon'})\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # find biggest polygon\n",
    "    big_shape = select_big_from_MP(WS_geometry=shape)\n",
    "\n",
    "    # find extent coordinates\n",
    "    min_LON, max_LON, min_LAT, max_LAT = find_extent(ws=big_shape)\n",
    "\n",
    "    # select nc inside of extent\n",
    "    masked_nc = nc.where(\n",
    "        nc.lat >= min_LAT, drop=True).where(\n",
    "        nc.lat <= max_LAT, drop=True).where(\n",
    "        nc.lon >= min_LON, drop=True).where(\n",
    "        nc.lon <= max_LON, drop=True)\n",
    "    masked_nc = masked_nc.chunk(chunks='auto')\n",
    "    return masked_nc\n",
    "\n",
    "\n",
    "def RotM(alpha):\n",
    "    \"\"\" Rotation Matrix for angle ``alpha`` \"\"\"\n",
    "    sa, ca = np.sin(alpha), np.cos(alpha)\n",
    "    return np.array([[ca, -sa],\n",
    "                     [sa,  ca]])\n",
    "\n",
    "\n",
    "def getSquareVertices(mm, h, phi):\n",
    "    \"\"\" Calculate the for vertices for square with center ``mm``,\n",
    "        side length ``h`` and rotation ``phi`` \"\"\"\n",
    "    hh0 = np.ones(2)*h  # initial corner\n",
    "    vv = [np.asarray(mm) + reduce(np.dot, [RotM(phi), RotM(np.pi/2*c), hh0])\n",
    "          for c in range(4)]  # rotate initial corner four times by 90Â°\n",
    "    return np.asarray(vv)\n",
    "\n",
    "\n",
    "def ERA_5_time_series_for_WS(ws_ID_row, geometry_row, ERA5_nc, path_to_save):\n",
    "\n",
    "    variables = list(ERA5_nc.data_vars)\n",
    "\n",
    "    if len(variables) != 1:\n",
    "        print('Something went wrong {}'.format(variables))\n",
    "    else:\n",
    "        start_time = time.time()\n",
    "        print('\\nVariable {} starts calculation'.format(variables[0]))\n",
    "        # redefine path_to_save\n",
    "        # path_to_save = path_to_save + variables[0]\n",
    "\n",
    "        os.makedirs(path_to_save, exist_ok=True)\n",
    "\n",
    "        for ii, test_shape in enumerate(tq.tqdm(geometry_row)):\n",
    "            # transform selected shape to geodataframe\n",
    "            # for further manipulations\n",
    "            big_shape = create_GDF(test_shape)\n",
    "            # use mask on net_cdf\n",
    "            with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "                mask_nc = select_NC_by_extent(nc=ERA5_nc[variables[0]],\n",
    "                                              shape=test_shape)\n",
    "\n",
    "            # get lat, lon which help define area for intersection\n",
    "            nc_lat, nc_lon = mask_nc.lat.values, mask_nc.lon.values\n",
    "\n",
    "            # emulate polygons for ERA5 grid\n",
    "            polygons = list()\n",
    "            for j in range(nc_lat.size):\n",
    "                for i in range(nc_lon.size):\n",
    "                    # h = 0.125 as a half of ERA5 resolution\n",
    "                    # phi rotation angle\n",
    "                    polygons.append(Polygon(getSquareVertices(mm=(nc_lon[i], nc_lat[j]),\n",
    "                                                              h=0.125,\n",
    "                                                              phi=0)))\n",
    "            # create geodataframe from each polygon from emulation\n",
    "            polygons = [create_GDF(poly) for poly in polygons]\n",
    "            # find intersection beetween grid cell and actual watershed\n",
    "\n",
    "            intersected = list()\n",
    "            for polygon in polygons:\n",
    "                try:\n",
    "                    intersected.append(gpd.overlay(df1=big_shape,\n",
    "                                                   df2=polygon,\n",
    "                                                   how='intersection'))\n",
    "                except KeyError:\n",
    "                    intersected.append(gpd.GeoDataFrame())\n",
    "            # find biggest intersection if it returns MultiPolygon instance\n",
    "            # convert to Polygon\n",
    "            intersected = [select_big_from_MP(section['geometry'][0])\n",
    "                           if len(section) != 0\n",
    "                           else gpd.GeoDataFrame()\n",
    "                           for section in intersected]\n",
    "\n",
    "            # create mask for intersection with net_cdf\n",
    "            inter_mask = np.array([section.empty != True\n",
    "                                   for section in intersected])\n",
    "            # [1:3] is used because first dimension is time\n",
    "            inter_mask = inter_mask.reshape(mask_nc.shape[1:3])\n",
    "            inter_mask = xr.DataArray(data=inter_mask,\n",
    "                                      dims=['lat', 'lon'],\n",
    "                                      coords=[nc_lat, nc_lon])\n",
    "            # create final instersection\n",
    "            WS_nc = mask_nc.where(inter_mask, drop=True)\n",
    "\n",
    "            # calculate weights of each intersection correspond to ERA grid cell\n",
    "            weights = np.array([0 if isinstance(section, gpd.GeoDataFrame)\n",
    "                                else polygon_area(lats=section.exterior.xy[1],\n",
    "                                                  lons=section.exterior.xy[0]) /\n",
    "                                polygon_area(lats=polygons[i]['geometry'][0].exterior.xy[1],\n",
    "                                             lons=polygons[i]['geometry'][0].exterior.xy[0])\n",
    "                                for i, section in enumerate(intersected)])\n",
    "            # transform to form on NetCDF\n",
    "            weights = weights.reshape(WS_nc.shape[1:3])\n",
    "            # transform to DataArray for calculations\n",
    "            weights = xr.DataArray(data=weights,\n",
    "                                   dims=['lat', 'lon'])\n",
    "            weights.name = 'weights'\n",
    "\n",
    "            if 't2m' in variables:\n",
    "                # record DataFrame\n",
    "                result_df = pd.DataFrame()\n",
    "                result_df['date'] = WS_nc.time.values\n",
    "                result_df[variables[0]] = (\n",
    "                    (WS_nc * weights).sum(dim=['lat', 'lon']) / np.sum(weights)).values\n",
    "                if os.path.isfile('{}/{}.csv'.format(path_to_save,\n",
    "                                                     ws_ID_row.loc[ii])):\n",
    "                    pass\n",
    "                else:\n",
    "                    result_df.to_csv('{}/{}.csv'.format(path_to_save,\n",
    "                                                        ws_ID_row.loc[ii]),\n",
    "                                     index=False)\n",
    "                end_time = time.time()\n",
    "            else:\n",
    "                # record DataFrame\n",
    "                result_df = pd.DataFrame()\n",
    "                result_df['date'] = WS_nc.time.values\n",
    "                result_df[variables[0]] = (\n",
    "                    (WS_nc * weights).sum(dim=['lat', 'lon']))\n",
    "                if os.path.isfile('{}/{}.csv'.format(path_to_save,\n",
    "                                                     ws_ID_row.loc[ii])):\n",
    "                    pass\n",
    "                else:\n",
    "                    result_df.to_csv('{}/{}.csv'.format(path_to_save,\n",
    "                                                        ws_ID_row.loc[ii]),\n",
    "                                     index=False)\n",
    "                end_time = time.time()\n",
    "        print(\"Variable {} successfully calculated in {:.2f} minutes\".format(variables[0],\n",
    "                                                                             (end_time - start_time) / 60))\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conus_basin_path = \"S:/education/HSI/aspirantura/Dissertation/conus_data/basin_set_full_res/HCDN_nhru_final_671.shp\"\n",
    "CONUS_WS = gpd.read_file(conus_basin_path)\n",
    "# select only biggest polygon from mulitipolygons file\n",
    "# if any exists\n",
    "CONUS_WS['geometry'] = [select_big_from_MP(ws) \n",
    "                         for ws in CONUS_WS['geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get variables for computation\n",
    "var_names = [i.split('\\\\')[-1] \n",
    "             for i in \n",
    "             glob.glob('E:/ERA5_data/CONUS/daily/*')]\n",
    "# define paths\n",
    "data_paths = ('E:/ERA5_data/CONUS/daily/2m_temperature/*.nc',\n",
    "              'E:/ERA5_data/CONUS/daily/2m_temperature_max/*.nc',\n",
    "              'E:/ERA5_data/CONUS/daily/2m_temperature_min/*.nc',\n",
    "              'E:/ERA5_data/CONUS/daily/evaporation/*.nc',\n",
    "              'E:/ERA5_data/CONUS/daily/potential_evaporation/*.nc',\n",
    "              'E:/ERA5_data/CONUS/daily/runoff/*.nc',\n",
    "              'E:/ERA5_data/CONUS/daily/total_precipitation/*.nc',\n",
    "              'E:/ERA5_data/CONUS/daily/mean_surface_direct_short_wave_radiation_flux/*.nc',\n",
    "              'E:/ERA5_data/CONUS/daily/mean_surface_direct_short_wave_radiation_flux/*.nc',\n",
    "              'E:/ERA5_data/CONUS/daily/mean_surface_direct_short_wave_radiation_flux_max/*.nc',\n",
    "              'E:/ERA5_data/CONUS/daily/mean_surface_direct_short_wave_radiation_flux_min/*.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculation for mean_surface_direct_short_wave_radiation_flux files\n",
      "\n",
      "Variable msdrswrf starts calculation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b5cc65c3204209ab18c58ed1e2f7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable msdrswrf successfully calculated in 19.71 minutes\n",
      "\n",
      "Calculation for mean_surface_direct_short_wave_radiation_flux_max files\n",
      "\n",
      "Variable msdrswrf starts calculation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe4a47a871e4bd7a57dbb6ec4e1c992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable msdrswrf successfully calculated in 457.71 minutes\n",
      "\n",
      "Calculation for mean_surface_direct_short_wave_radiation_flux_min files\n",
      "\n",
      "Variable msdrswrf starts calculation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b203346690674fb9a9f71b1beb138b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/671 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable msdrswrf successfully calculated in 15.97 minutes\n"
     ]
    }
   ],
   "source": [
    "for i, path in enumerate(data_paths):\n",
    "    print('\\nCalculation for {} files'.format(var_names[i]))\n",
    "    nc_data = xr.open_mfdataset(paths=path,\n",
    "                                engine='netcdf4',\n",
    "                                chunks='auto')\n",
    "    ERA_5_time_series_for_WS(ws_ID_row=CONUS_WS['hru_id'],\n",
    "                             geometry_row=CONUS_WS['geometry'],\n",
    "                             ERA5_nc=nc_data,\n",
    "                             path_to_save='S:/education/HSI/aspirantura/Dissertation/conus_data/WS_by_VARIABLE/{data_fodler}'.format(data_fodler=path.split('/')[-2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0dfc7d7d7c3a4a6eb03a27f98f53fdb9f43304f8b489db059476e3936ddfb4c9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ERA': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
